{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT = 0.2\n",
    "MAX_NB_WORDS = 10000\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "EMBEDDING_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readXML(path):\n",
    "    \"\"\"\n",
    "    Read XML file into a dictionary\n",
    "    \"\"\"\n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    dataset = pd.DataFrame(columns=['QID', 'QAID'], dtype=int)\n",
    "    \n",
    "    for Question in root:\n",
    "        QID = int(Question.get('QID'))\n",
    "        Qtext = Question.find('Qtext').text\n",
    "        \n",
    "        for QApair in Question.iter('QApair'): \n",
    "            QAID = int(QApair.get('QAID'))\n",
    "            QArel = QApair.get('QArel')\n",
    "            QAconf = QApair.get('QAconf')\n",
    "            QAquestion = QApair.find('QAquestion').text\n",
    "            QAanswer = QApair.find('QAanswer').text\n",
    "            QAdiff = ' '.join([w for w in (QAquestion + ' ' + QAanswer).split() if w in Qtext.split()])\n",
    "            \n",
    "            dataset = dataset.append({'QID': QID,\n",
    "                                    'QAID': QAID,\n",
    "                                    'Qtext': Qtext,\n",
    "                                    'QAquestion': QAquestion,\n",
    "                                    'QAanswer': QAanswer,\n",
    "                                    'QArel': 0 if QArel == 'I' else 1,\n",
    "                                    'QAconf': QAconf,\n",
    "                                    'QAdiff': QAdiff}, ignore_index=True)\n",
    "            \n",
    "    dataset.set_index(['QID', 'QAID'], inplace=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = readXML('../TRAIN/SemEval2016-Task3-CQA-MD-train.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = readXML('../TEST/2017/SemEval2017-Task3-CQA-MD-test.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 86378 unique tokens.\n",
      "Training Set:\n",
      "Shape of query tensor: (30411, 314)\n",
      "Shape of question tensor: (30411, 314)\n",
      "Shape of label tensor: (30411,)\n",
      "Test Set:\n",
      "Shape of query tensor: (12600, 314)\n",
      "Shape of question tensor: (12600, 314)\n",
      "Shape of label tensor: (12600,)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "texts_query_train = train_dataset['Qtext'] \n",
    "texts_question_train = train_dataset['QAquestion']\n",
    "texts_diff_train = train_dataset['QAdiff']\n",
    "labels_train = train_dataset['QArel']\n",
    "\n",
    "texts_query_test = test_dataset['Qtext']\n",
    "texts_question_test = test_dataset['QAquestion']\n",
    "texts_diff_test = test_dataset['QAdiff']\n",
    "labels_test = test_dataset['QArel']\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts_query_train.append(texts_question_train.append(texts_query_test.append(texts_question_test))))\n",
    "tokenizer.fit_on_texts(texts_diff_train.append(texts_diff_test))\n",
    "\n",
    "sequences_query_train = tokenizer.texts_to_sequences(texts_query_train)\n",
    "sequences_question_train = tokenizer.texts_to_sequences(texts_question_train)\n",
    "sequences_diff_train = tokenizer.texts_to_sequences(texts_diff_train)\n",
    "sequences_query_test = tokenizer.texts_to_sequences(texts_query_test)\n",
    "sequences_question_test = tokenizer.texts_to_sequences(texts_question_test)\n",
    "sequences_diff_test = tokenizer.texts_to_sequences(texts_diff_test)\n",
    "\n",
    "\n",
    "#MAX_SEQUENCE_LENGTH = max(map(len, (x for x in sequences_query_train + sequences_question_train + sequences_query_test + sequences_question_test)))\n",
    "MAX_SEQUENCE_LENGTH = max(map(len, (x for x in sequences_diff_train + sequences_diff_test)))\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data_query_train = pad_sequences(sequences_query_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "data_question_train = pad_sequences(sequences_question_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "data_diff_train = pad_sequences(sequences_diff_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "data_query_test = pad_sequences(sequences_query_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "data_question_test = pad_sequences(sequences_question_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "data_diff_test = pad_sequences(sequences_diff_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labels_train = np.asarray(labels_train)\n",
    "labels_test = np.asarray(labels_test)\n",
    "\n",
    "print('Training Set:')\n",
    "print('Shape of query tensor:', data_query_train.shape)\n",
    "print('Shape of question tensor:', data_question_train.shape)\n",
    "print('Shape of label tensor:', labels_train.shape)\n",
    "\n",
    "print('Test Set:')\n",
    "print('Shape of query tensor:', data_query_test.shape)\n",
    "print('Shape of question tensor:', data_question_test.shape)\n",
    "print('Shape of label tensor:', labels_test.shape)\n",
    "\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data_query_train.shape[0])\n",
    "\n",
    "x_query_train = data_query_train[:-nb_validation_samples]\n",
    "x_question_train = data_question_train[:-nb_validation_samples]\n",
    "x_diff_train = data_diff_train[:-nb_validation_samples]\n",
    "y_train = labels_train[:-nb_validation_samples].reshape(-1, 1)\n",
    "x_query_val = data_query_train[-nb_validation_samples:]\n",
    "x_question_val = data_question_train[-nb_validation_samples:]\n",
    "x_diff_val = data_diff_train[-nb_validation_samples:]\n",
    "y_val = labels_train[-nb_validation_samples:].reshape(-1, 1)\n",
    "x_query_test = data_query_test\n",
    "x_question_test = data_question_test\n",
    "x_diff_test = data_diff_test\n",
    "y_test = labels_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "embeddings = pickle.load(open('embeddings.pic', 'rb'))\n",
    "dictionary = pickle.load(open('dictionary.pic', 'rb'))\n",
    "\n",
    "for word in dictionary.keys():\n",
    "    embeddings_index[word] = embeddings[dictionary[word]]\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86378"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 128)         11056512  \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 16)                6576      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 11,063,105\n",
      "Trainable params: 6,593\n",
      "Non-trainable params: 11,056,512\n",
      "_________________________________________________________________\n",
      "Train on 24329 samples, validate on 6082 samples\n",
      "Epoch 1/20\n",
      "24329/24329 [==============================] - 63s 3ms/step - loss: 0.6728 - acc: 0.5964 - val_loss: 0.6566 - val_acc: 0.6200\n",
      "Epoch 2/20\n",
      "24329/24329 [==============================] - 62s 3ms/step - loss: 0.6626 - acc: 0.5984 - val_loss: 0.6488 - val_acc: 0.6200\n",
      "Epoch 3/20\n",
      "24329/24329 [==============================] - 67s 3ms/step - loss: 0.6547 - acc: 0.6011 - val_loss: 0.6407 - val_acc: 0.6273\n",
      "Epoch 4/20\n",
      "24329/24329 [==============================] - 67s 3ms/step - loss: 0.6494 - acc: 0.6116 - val_loss: 0.6340 - val_acc: 0.6391\n",
      "Epoch 5/20\n",
      "24329/24329 [==============================] - 68s 3ms/step - loss: 0.6460 - acc: 0.6189 - val_loss: 0.6306 - val_acc: 0.6432\n",
      "Epoch 6/20\n",
      "24329/24329 [==============================] - 97s 4ms/step - loss: 0.6437 - acc: 0.6237 - val_loss: 0.6288 - val_acc: 0.6498\n",
      "Epoch 7/20\n",
      "24329/24329 [==============================] - 81s 3ms/step - loss: 0.6425 - acc: 0.6237 - val_loss: 0.6274 - val_acc: 0.6498\n",
      "Epoch 8/20\n",
      "24329/24329 [==============================] - 77s 3ms/step - loss: 0.6406 - acc: 0.6286 - val_loss: 0.6268 - val_acc: 0.6518\n",
      "Epoch 9/20\n",
      "24329/24329 [==============================] - 70s 3ms/step - loss: 0.6404 - acc: 0.6271 - val_loss: 0.6259 - val_acc: 0.6532\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense, GRU, Conv1D, MaxPooling1D, GlobalMaxPool1D, concatenate, Input, Bidirectional\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix], trainable=False))\n",
    "model.add(Bidirectional(GRU(8, activation='relu', recurrent_dropout=0.5, dropout=0.5)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "callbacks_list = [\n",
    "    EarlyStopping(\n",
    "        monitor='acc',\n",
    "        patience=1,\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath='data/best_model.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(x_diff_train, y_train, validation_data=(x_diff_val, y_val),\n",
    "    epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.load_weights(filepath='BiGRU.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_test = model.predict(x_diff_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataset = test_dataset\n",
    "pred_dataset['Score'] = [0 if score[0] < 0 or math.isnan(score[0]) else round(score[0],4) for score in scores_test ]\n",
    "pred_dataset['Relevance'] = ['true' if score[0] > 0.5 else 'false' for score in scores_test]\n",
    "pred_dataset['Rank'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataset = pred_dataset.sort_index(level=0, ascending=[False, True])\n",
    "pred_dataset = pred_dataset.reset_index().drop_duplicates().set_index(['QID', 'QAID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_dataset = pd.read_csv('../EVAL/SemEval2017-Task3-CQA-MD-test.xml.subtaskD.relevancy', sep='\\t',  names=['QID', 'QAID', 'Rank', 'Score', 'Relevance'], index_col=['QID', 'QAID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_score(gold_dataset, pred_dataset, th=10):\n",
    "    dataset = pred_dataset.join(gold_dataset, lsuffix='_pred', rsuffix='_gold')[['Score_pred', 'Relevance_gold']].reset_index()\n",
    "    dataset = dataset.sort_values(['QID', 'Score_pred'], ascending=False)\n",
    "    dataset['Rank_pred'] = dataset.groupby('QID')['Score_pred'].rank(ascending=False)\n",
    "    dataset = dataset[dataset.Relevance_gold]\n",
    "    dataset = dataset[dataset.Rank_pred <= th]\n",
    "    dataset['Position'] = dataset.groupby('QID')['Rank_pred'].rank(ascending=True)\n",
    "    dataset['Precision'] = dataset.Position / dataset.Rank_pred\n",
    "    AP = dataset.groupby('QID')['Precision'].mean()\n",
    "    return round(AP.sum() / len(pred_dataset.groupby('QID')),4) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "qid = pred_dataset.reset_index()['QID']\n",
    "qaid = pred_dataset.reset_index()['QAID']\n",
    "y = pred_dataset.reset_index()['QArel']\n",
    "ypred = pred_dataset.reset_index()['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mAP = map_score(gold_dataset, pred_dataset)\n",
    "accuracy = 100 * accuracy_score(y == 1, ypred >= 0.5)\n",
    "precision = 100 * precision_score(y == 1, ypred >= 0.5)\n",
    "recall = 100 * recall_score(y == 1, ypred >= 0.5)\n",
    "F1 = 100 * f1_score(y == 1, ypred >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 56.80\n",
      "Accuracy: 55.71\n",
      "Precision: 46.32\n",
      "Recall: 81.08\n",
      "F1: 58.96\n"
     ]
    }
   ],
   "source": [
    "print('MAP: %.2f\\nAccuracy: %.2f\\nPrecision: %.2f\\nRecall: %.2f\\nF1: %.2f' % (mAP, accuracy, precision, recall, F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
