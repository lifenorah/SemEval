{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import msgpack\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vocabulary w/ word frequencies\n",
    "with open('wmt11.head.vocab', 'rb') as f:\n",
    "    vocab = msgpack.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load requisite vector data\n",
    "with open('wmt11.head.vectors', 'rb') as f:\n",
    "    W = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = dict((id, word) for word, (id, _) in vocab.iteritems())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize word vectors\n",
    "for i, row in enumerate(W):\n",
    "    W[i, :] /= np.linalg.norm(row)\n",
    "    \n",
    "# Remove context word vectors\n",
    "W = W[:len(vocab), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(positive, negative, topn=10, freq_threshold=5):\n",
    "    # Build a \"mean\" vector for the given positive and negative terms\n",
    "    mean_vecs = []\n",
    "    for word in positive: mean_vecs.append(W[vocab[word][0]])\n",
    "    for word in negative: mean_vecs.append(-1 * W[vocab[word][0]])\n",
    "    \n",
    "    mean = np.array(mean_vecs).mean(axis=0)\n",
    "    mean /= np.linalg.norm(mean)\n",
    "    \n",
    "    # Now calculate cosine distances between this mean vector and all others\n",
    "    dists = np.dot(W, mean)\n",
    "    \n",
    "    best = np.argsort(dists)[::-1][:topn + len(positive) + len(negative) + 100]\n",
    "    result = [(id2word[i], dists[i]) for i in best if (vocab[id2word[i]] >= freq_threshold\n",
    "                                                       and id2word[i] not in positive\n",
    "                                                       and id2word[i] not in negative)]\n",
    "    return result[:topn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar(['king', 'woman'], ['man'], topn=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar(['brought', 'seek'], ['bring'], topn=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "import evaluate\n",
    "import glove\n",
    "\n",
    "\n",
    "# Mock corpus (shamelessly stolen from Gensim word2vec tests)\n",
    "test_corpus = (\"\"\"human interface computer\n",
    "survey user computer system response time\n",
    "eps user interface system\n",
    "system human system eps\n",
    "user response time\n",
    "trees\n",
    "graph trees\n",
    "graph minors trees\n",
    "graph minors survey\n",
    "I like graph and stuff\n",
    "I like trees and stuff\n",
    "Sometimes I build a graph\n",
    "Sometimes I build trees\"\"\").split(\"\\n\")\n",
    "\n",
    "glove.logger.setLevel(logging.ERROR)\n",
    "vocab = glove.build_vocab(test_corpus)\n",
    "cooccur = glove.build_cooccur(vocab, test_corpus, window_size=10)\n",
    "id2word = evaluate.make_id2word(vocab)\n",
    "\n",
    "W = glove.train_glove(vocab, cooccur, vector_size=10, iterations=500)\n",
    "\n",
    "# Merge and normalize word vectors\n",
    "W = evaluate.merge_main_context(W)\n",
    "\n",
    "\n",
    "def test_similarity():\n",
    "    similar = evaluate.most_similar(W, vocab, id2word, 'graph')\n",
    "    logging.debug(similar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.76863036e-01,   1.06420739e-01,  -5.68388346e-02,\n",
       "         -3.25742154e-01,   5.66774998e-01,   8.34974421e-02,\n",
       "          5.12050915e-01,  -1.45726657e-01,   1.37232722e-01,\n",
       "          4.66459590e-01],\n",
       "       [  1.86942051e-02,  -1.32604399e-01,   1.46012603e-01,\n",
       "          2.10063053e-01,  -3.67849356e-02,   5.00128860e-01,\n",
       "          2.31580088e-01,   2.64782724e-01,   9.09439805e-02,\n",
       "          7.30156414e-01],\n",
       "       [ -3.21640051e-01,   4.21456363e-01,   2.62546959e-01,\n",
       "          4.48856056e-01,  -1.37258049e-01,  -5.14317641e-01,\n",
       "         -1.62838295e-01,  -1.43768005e-01,   9.42472382e-02,\n",
       "         -3.30286312e-01],\n",
       "       [  4.46461637e-01,  -2.46975138e-02,   1.93156120e-01,\n",
       "          1.05366072e-01,  -9.74688845e-02,   3.16066382e-01,\n",
       "         -1.59454129e-01,   5.11101031e-01,  -1.61036659e-01,\n",
       "          5.74168890e-01],\n",
       "       [  1.45025910e-01,  -3.38898352e-01,   3.98213183e-01,\n",
       "          4.96835855e-02,  -4.47507024e-01,   4.22373595e-02,\n",
       "         -3.69258732e-01,  -3.41802121e-01,   4.51156349e-01,\n",
       "          2.10484944e-01],\n",
       "       [ -4.16132882e-01,  -1.76621224e-02,   2.08067208e-01,\n",
       "          3.65235351e-01,   4.71478089e-01,   2.08194763e-01,\n",
       "         -2.07679204e-01,  -3.95892827e-01,   2.53210918e-01,\n",
       "         -3.46725323e-01],\n",
       "       [ -5.40393046e-02,  -2.33137823e-01,  -5.20016149e-01,\n",
       "         -2.11562710e-01,  -2.06624969e-01,  -1.17389638e-01,\n",
       "          7.63547577e-02,  -5.55435244e-01,   4.98785033e-01,\n",
       "         -8.91731960e-02],\n",
       "       [ -1.09640970e-01,   4.30740619e-02,   1.60820792e-01,\n",
       "          1.24700203e-01,   1.02191864e-01,   2.09928329e-01,\n",
       "          3.71199151e-01,   7.29650714e-01,  -4.67699741e-01,\n",
       "         -3.57059247e-02],\n",
       "       [  2.43793750e-01,  -1.26724951e-01,   4.97166645e-01,\n",
       "         -9.04082413e-02,  -5.00757550e-02,  -3.43795329e-01,\n",
       "         -2.44105487e-01,  -6.14155495e-01,   1.62853014e-01,\n",
       "          2.91819631e-01],\n",
       "       [  1.31297236e-03,  -2.62612892e-01,   1.77399094e-01,\n",
       "          1.96134554e-01,  -6.72945386e-01,   4.05349924e-02,\n",
       "         -1.20057724e-01,  -2.16314898e-01,  -3.54309101e-01,\n",
       "         -4.68885951e-01],\n",
       "       [ -5.15932654e-02,   3.82180167e-01,  -1.64136386e-01,\n",
       "         -4.90086802e-01,   2.69969661e-01,  -2.82760272e-01,\n",
       "          2.71800321e-01,   4.74693963e-02,   1.74232100e-01,\n",
       "         -5.69936888e-01],\n",
       "       [ -3.68736310e-01,  -1.91352727e-01,  -2.97244277e-01,\n",
       "          3.71636432e-01,  -4.31239339e-01,  -2.90559815e-02,\n",
       "          2.23223222e-01,  -5.10778495e-02,  -1.69457184e-01,\n",
       "         -5.77048492e-01],\n",
       "       [  1.98617550e-01,  -3.22131205e-01,  -2.35266758e-01,\n",
       "         -3.07448289e-01,   4.29664028e-01,  -1.26656766e-01,\n",
       "          5.21800066e-01,   4.15663802e-02,   6.33973465e-02,\n",
       "          4.77736589e-01],\n",
       "       [  1.99841080e-01,  -1.76277121e-02,  -1.88285227e-01,\n",
       "          2.30474845e-01,  -3.82951068e-01,  -4.06084660e-01,\n",
       "         -5.76552425e-02,  -5.56584193e-02,  -8.20028916e-02,\n",
       "         -7.39242919e-01],\n",
       "       [ -5.30312905e-01,   2.99243743e-02,   4.47505096e-01,\n",
       "          3.54848127e-01,   2.67092980e-01,   3.29567480e-01,\n",
       "         -7.22106682e-02,  -3.06813662e-01,   3.30983322e-01,\n",
       "         -5.33141899e-02],\n",
       "       [  3.19495575e-03,  -1.07371746e-01,   2.10550496e-01,\n",
       "          2.04972420e-01,   7.13613681e-02,   4.90344371e-01,\n",
       "         -5.80429303e-04,   6.15258261e-01,  -3.25014703e-01,\n",
       "          4.15220698e-01],\n",
       "       [ -1.49817265e-01,   9.73547665e-02,  -2.34951776e-01,\n",
       "         -3.02693068e-01,   2.05966580e-01,   7.22874771e-01,\n",
       "          5.40193332e-02,   4.87112731e-01,   8.34781059e-02,\n",
       "          9.54764035e-02],\n",
       "       [ -2.37151373e-01,   3.67862574e-01,  -2.25745815e-01,\n",
       "         -4.87217980e-01,   1.90139182e-01,  -3.47523992e-01,\n",
       "          2.78060904e-01,   1.50220504e-01,   9.43101046e-02,\n",
       "         -5.04370424e-01],\n",
       "       [  1.79329862e-01,  -2.35907975e-01,   4.39547579e-01,\n",
       "         -4.15382251e-02,  -2.44845768e-01,  -2.68337087e-01,\n",
       "         -3.40881067e-01,  -5.15711258e-01,   3.84046075e-01,\n",
       "          2.35917563e-01]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
