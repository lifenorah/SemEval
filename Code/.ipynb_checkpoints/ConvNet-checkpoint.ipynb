{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from keras.layers import Input, Merge\n",
    "from keras.layers.core import Activation, Dense, Dropout, Permute\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.merge import add, concatenate, dot\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "import collections\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import h5py\n",
    "import PyArabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(infile):\n",
    "    tree = ET.parse(infile)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    stories, questions, answers = [], [], []\n",
    "\n",
    "    for Question in root:\n",
    "        QID = int(Question.get('QID'))\n",
    "        Qtext = Question.find('Qtext').text\n",
    "\n",
    "        for QApair in Question.iter('QApair'): \n",
    "            QAID = int(QApair.get('QAID'))\n",
    "            QArel = QApair.get('QArel')\n",
    "            QAquestion = QApair.find('QAquestion').text\n",
    "            QAanswer = QApair.find('QAanswer').text\n",
    "\n",
    "            stories.append(Qtext)\n",
    "            questions.append(QAquestion)\n",
    "            answers.append(QArel)\n",
    "    return stories, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../TRAIN\"\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, \"SemEval2016-Task3-CQA-MD-train.xml\")\n",
    "TEST_FILE = os.path.join(DATA_DIR, \"SemEval2017-Task3-CQA-MD-test.xml\")\n",
    "\n",
    "# get the data\n",
    "data_train = get_data(TRAIN_FILE)\n",
    "data_test = get_data(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(train_data, test_data):\n",
    "    counter = collections.Counter()\n",
    "    for stories, questions, answers in [train_data, test_data]:\n",
    "        for story in stories:\n",
    "            for sent in story:\n",
    "                for word in [w for w in sent.split() if w not in stopwords]:\n",
    "                    word = preprocessor.deNoise(word)\n",
    "                    counter[word.lower()] += 1\n",
    "        for question in questions:\n",
    "            for word in [w for w in question.split() if w not in stopwords]:\n",
    "                word = preprocessor.deNoise(word)\n",
    "                counter[word.lower()]+= 1\n",
    "        for answer in answers:\n",
    "            for word in [w for w in answer.split() if w not in stopwords]:\n",
    "                word = preprocessor.deNoise(word)\n",
    "                counter[word.lower()] += 1\n",
    "    # no OOV here because there are not too many words in dataset\n",
    "    word2idx = {w:(i+1) for i, (w, _) in enumerate(counter.most_common())}\n",
    "    word2idx[\"PAD\"] = 0\n",
    "    idx2word = {v:k for k, v in word2idx.items()}\n",
    "    return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maxlens(train_data, test_data):\n",
    "    story_maxlen, question_maxlen = 0, 0\n",
    "    for stories, questions, _ in [train_data, test_data]:\n",
    "        for story in stories:\n",
    "            story_len = 0\n",
    "            for sent in story:\n",
    "                swords = sent.split()\n",
    "                story_len += len(swords)\n",
    "            if story_len > story_maxlen:\n",
    "                story_maxlen = story_len\n",
    "        for question in questions:\n",
    "            question_len = len(question.split())\n",
    "            if question_len > question_maxlen:\n",
    "                question_maxlen = question_len\n",
    "    return story_maxlen, question_maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
    "    Xs, Xq, Y = [], [], []\n",
    "    stories, questions, answers = data\n",
    "    for story, question, answer in zip(stories, questions, answers):\n",
    "        xs = [[word2idx[preprocessor.deNoise(w.lower())] for w in s.split() if w not in stopwords] \n",
    "                                   for s in story]\n",
    "        xs = list(itertools.chain.from_iterable(xs))\n",
    "        xq = [word2idx[preprocessor.deNoise(w.lower())] for w in question.split() if w not in stopwords]\n",
    "        Xs.append(xs)\n",
    "        Xq.append(xq)\n",
    "        Y.append(0 if answer == 'I' else 1)\n",
    "    return pad_sequences(Xs, maxlen=story_maxlen),\\\n",
    "           pad_sequences(Xq, maxlen=question_maxlen),\\\n",
    "           Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30411 12600\n",
      "vocab size: 83416\n",
      "story maxlen: 1223, question maxlen: 865\n",
      "(30411, 1223) (30411, 865) 30411 (12600, 1223) (12600, 865) 12600\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"../TRAIN\"\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, \"SemEval2016-Task3-CQA-MD-train.xml\")\n",
    "TEST_FILE = os.path.join(DATA_DIR, \"SemEval2017-Task3-CQA-MD-test.xml\")\n",
    "\n",
    "# get the data\n",
    "data_train = get_data(TRAIN_FILE)\n",
    "data_test = get_data(TEST_FILE)\n",
    "\n",
    "print(len(data_train[0]), len(data_test[0]))\n",
    "\n",
    "with open('stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = f.readlines()\n",
    "        \n",
    "preprocessor = PyArabic.ArabicPreprocessor()\n",
    "\n",
    "# build vocabulary from all the data\n",
    "word2idx, idx2word = build_vocab(data_train, data_test)\n",
    "\n",
    "vocab_size = len(word2idx)\n",
    "print(\"vocab size: {:d}\".format(len(word2idx)))\n",
    "\n",
    "# compute max sequence length for each entity\n",
    "story_maxlen, question_maxlen = get_maxlens(data_train, data_test)\n",
    "print(\"story maxlen: {:d}, question maxlen: {:d}\".format(story_maxlen, question_maxlen))\n",
    "\n",
    "# vectorize the data\n",
    "Xstrain, Xqtrain, Ytrain = vectorize(data_train, word2idx, story_maxlen, question_maxlen)\n",
    "Xstest, Xqtest, Ytest = vectorize(data_test, word2idx, story_maxlen, question_maxlen)\n",
    "\n",
    "print(Xstrain.shape, Xqtrain.shape, len(Ytrain), Xstest.shape, Xqtest.shape, len(Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_119 (InputLayer)           (None, 1223)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_120 (InputLayer)           (None, 865)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_87 (Sequential)       multiple              5338624     input_119[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "sequential_88 (Sequential)       (None, 865, 64)       5338624     input_120[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lstm_56 (LSTM)                   (None, 64)            33024       sequential_87[1][0]              \n",
      "                                                                   sequential_88[1][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)     (None, 128)           0           lstm_56[0][0]                    \n",
      "                                                                   lstm_56[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_37 (Dense)                 (None, 1)             129         concatenate_23[0][0]             \n",
      "====================================================================================================\n",
      "Total params: 10,710,401\n",
      "Trainable params: 10,710,401\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### define network\n",
    "EMBEDDING_SIZE = 64\n",
    "LATENT_SIZE = 32\n",
    "BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# placeholders\n",
    "original_sequence = Input((story_maxlen,))\n",
    "question_sequence = Input((question_maxlen,))\n",
    "\n",
    "# encoders\n",
    "\n",
    "# embed the original question into a sequence of vectors of size story_maxlen\n",
    "original_encoder = Sequential()\n",
    "original_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=64))\n",
    "# output: (samples, story_maxlen, query_maxlen)\n",
    "\n",
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                              input_length=question_maxlen))\n",
    "\n",
    "original_encoded = original_encoder(original_sequence)\n",
    "question_encoded = question_encoder(question_sequence)\n",
    "\n",
    "shared_lstm = LSTM(64)\n",
    "\n",
    "encoded_a = shared_lstm(original_encoded)\n",
    "encoded_b = shared_lstm(question_encoded)\n",
    "\n",
    "merged_vector = concatenate([encoded_a, encoded_b], axis=1)\n",
    "\n",
    "predictions = Dense(1, activation='sigmoid')(merged_vector)\n",
    "\n",
    "model = Model(inputs=[original_sequence, question_sequence], outputs=predictions)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24328 samples, validate on 6083 samples\n",
      "Epoch 1/5\n",
      " 3200/24328 [==>...........................] - ETA: 4891s - loss: 0.6752 - acc: 0.6075"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = model.fit([Xstrain, Xqtrain], Ytrain, batch_size=BATCH_SIZE, \n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    validation_split=0.2)\n",
    "                    \n",
    "# plot accuracy and loss plot\n",
    "plt.subplot(211)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model \n",
    "model.save('SemEval-MemNN-Model.h5')\n",
    "\n",
    "#save the weights\n",
    "model.save_weights('SemEval-MemNN-Weights.h5')\n",
    "\n",
    "#save the architecture\n",
    "model_json = model.to_json()\n",
    "with open(\"SemEval-MemNN-Arch.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-f910c62a4122>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# get predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mYtest_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mXstest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXqtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mNUM_DISPLAY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1711\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1712\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[1;32m-> 1713\u001b[1;33m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[0;32m   1714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1715\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[1;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1267\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1269\u001b[1;33m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1270\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2273\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# labels\n",
    "ytest = Ytest\n",
    "\n",
    "# get predictions\n",
    "Ytest_ = model.predict([Xstest, Xqtest])\n",
    "\n",
    "NUM_DISPLAY = 30\n",
    "\n",
    "for i in range(NUM_DISPLAY):\n",
    "    story = \" \".join([idx2word[x] for x in Xstest[i].tolist() if x != 0])\n",
    "    question = \" \".join([idx2word[x] for x in Xqtest[i].tolist()])\n",
    "    label = ytest[i]\n",
    "    prediction = Ytest_[i]\n",
    "    print(story[-20:], question[-20:], label, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_path = '../TEST/2017/SemEval2017-Task3-CQA-MD-test-input.xml'\n",
    "\n",
    "tree = ET.parse(test_dataset_path)\n",
    "root = tree.getroot()\n",
    "    \n",
    "for Question in root:\n",
    "    QID = int(Question.get('QID'))\n",
    "    Qtext = Question.find('Qtext').text\n",
    "    \n",
    "    for QApair in Question.iter('QApair'): \n",
    "        QAID = int(QApair.get('QAID'))\n",
    "        QArel = QApair.get('QArel')\n",
    "        QAquestion = QApair.find('QAquestion').text\n",
    "        QAanswer = QApair.find('QAanswer').text\n",
    "\n",
    "        Xquestion, Xqaquestion, _ = vectorize(([Qtext], [QAquestion], [0]), word2idx, story_maxlen, question_maxlen)\n",
    "        QAconf = np.asscalar(model.predict([Xquestion, Xqaquestion]))\n",
    "        \n",
    "        QApair.set('QArel', 'R' if QAconf >= 0.5 else 'I')\n",
    "        QApair.set('QAconf', str(round(QAconf, 4)))\n",
    "\n",
    "tree.write('../TEST/2017/SemEval2017-Task3-CQA-MD-test-input-MemNN.xml', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = u'لا'\n",
    "word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
