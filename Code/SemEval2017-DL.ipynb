{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, '../EVAL/scorer_v2.3/MAP_scripts/')\n",
    "from ev import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT = 0.2\n",
    "MAX_NB_WORDS = 20000\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "EMBEDDING_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readXML(path):\n",
    "    \"\"\"\n",
    "    Read XML file into a dictionary\n",
    "    \"\"\"\n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    dataset = pd.DataFrame(columns=['QID', 'QAID'], dtype=int)\n",
    "    \n",
    "    for Question in root:\n",
    "        QID = int(Question.get('QID'))\n",
    "        Qtext = Question.find('Qtext').text\n",
    "        \n",
    "        for QApair in Question.iter('QApair'): \n",
    "            QAID = int(QApair.get('QAID'))\n",
    "            QArel = QApair.get('QArel')\n",
    "            QAconf = QApair.get('QAconf')\n",
    "            QAquestion = QApair.find('QAquestion').text\n",
    "            QAanswer = QApair.find('QAanswer').text\n",
    "            \n",
    "            dataset = dataset.append({'QID': QID,\n",
    "                                    'QAID': QAID,\n",
    "                                    'Qtext': Qtext,\n",
    "                                    'QAquestion': QAquestion,\n",
    "                                    'QAanswer': QAanswer,\n",
    "                                    'QArel': 0 if QArel == 'I' else 1,\n",
    "                                    'QAconf': QAconf}, ignore_index=True)\n",
    "            \n",
    "    dataset.set_index(['QID', 'QAID'], inplace=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = readXML('../TRAIN/SemEval2016-Task3-CQA-MD-train.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = readXML('../TEST/2017/SemEval2017-Task3-CQA-MD-test.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "texts_train = train_dataset['Qtext'] + train_dataset['QAquestion']\n",
    "labels_train = train_dataset['QArel']\n",
    "\n",
    "texts_test = test_dataset['Qtext'] + test_dataset['QAquestion']\n",
    "labels_test = test_dataset['QArel']\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts_train.append(texts_test))\n",
    "\n",
    "sequences_train = tokenizer.texts_to_sequences(texts_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(texts_test)\n",
    "\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = max(map(len, (x for x in sequences_train + sequences_test)))\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data_train = pad_sequences(sequences_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "data_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labels_train = np.asarray(labels_train)\n",
    "labels_test = np.asarray(labels_test)\n",
    "\n",
    "print('Training Set:')\n",
    "print('Shape of data tensor:', data_train.shape)\n",
    "print('Shape of label tensor:', labels_train.shape)\n",
    "\n",
    "print('Test Set:')\n",
    "print('Shape of data tensor:', data_test.shape)\n",
    "print('Shape of label tensor:', labels_test.shape)\n",
    "\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data_train.shape[0])\n",
    "\n",
    "x_train = data_train[:-nb_validation_samples]\n",
    "y_train = labels_train[:-nb_validation_samples].reshape(-1, 1)\n",
    "x_val = data_train[-nb_validation_samples:]\n",
    "y_val = labels_train[-nb_validation_samples:].reshape(-1, 1)\n",
    "x_test = data_test\n",
    "y_test = labels_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "embeddings = pickle.load(open('embeddings.pic', 'rb'))\n",
    "dictionary = pickle.load(open('dictionary.pic', 'rb'))\n",
    "\n",
    "for word in dictionary.keys():\n",
    "    embeddings_index[word] = embeddings[dictionary[word]]\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                           EMBEDDING_DIM,\n",
    "                           weights=[embedding_matrix],\n",
    "                           input_length=MAX_SEQUENCE_LENGTH,\n",
    "                           trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, LSTM\n",
    "from keras import Model, Input, Sequential\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                           EMBEDDING_DIM,\n",
    "                           weights=[embedding_matrix],\n",
    "                           input_length=MAX_SEQUENCE_LENGTH,\n",
    "                           trainable=False))\n",
    "model.add(LSTM(5, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "         epochs=20, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_test = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset['score'] = [0 if score[0] < 0 or math.isnan(score[0]) else round(score[0],4) for score in scores_test ]\n",
    "test_dataset['relevance'] = ['true' if score[0] > 0.5 else 'false' for score in scores_test]\n",
    "test_dataset['rank'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.sort_index(level=0, ascending=[False, True])\n",
    "test_dataset = test_dataset.reset_index().drop_duplicates().set_index(['QID', 'QAID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.to_csv('../EVAL/SemEval2017-Task3-CQA-MD-test-cnn.xml.pred', sep='\\t', header=None, columns=['QID', 'QAID', 'rank', 'score', 'relevance' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "859.0191978458053\n"
     ]
    }
   ],
   "source": [
    "MAP, Accuracy, P, R, F1  = evaluate('../EVAL/SemEval2017-Task3-CQA-MD-test.xml.subtaskD.relevancy', '../EVAL/SemEval2017-Task3-CQA-MD-test-lsa-mlp.xml.pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.6136\n",
      "Accuracy: 0.6215\n",
      "Precision: 0.8295\n",
      "Recall: 0.0444\n",
      "F1: 0.0842\n"
     ]
    }
   ],
   "source": [
    "print(\"MAP: %5.4f\" % MAP)\n",
    "print(\"Accuracy: %5.4f\" % Accuracy)\n",
    "print(\"Precision: %5.4f\" % P)\n",
    "print(\"Recall: %5.4f\" % R)\n",
    "print(\"F1: %5.4f\" % F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "859.0191978458053 /"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
