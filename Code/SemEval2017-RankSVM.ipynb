{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python35\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.spatial.distance import cosine\n",
    "import xml.etree.ElementTree as ET\n",
    "import pickle\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import svm, linear_model, cross_validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_pairwise(X, y):\n",
    "    \"\"\"Transforms data into pairs with balanced labels for ranking\n",
    "    Transforms a n-class ranking problem into a two-class classification\n",
    "    problem. Subclasses implementing particular strategies for choosing\n",
    "    pairs should override this method.\n",
    "    In this method, all pairs are choosen, except for those that have the\n",
    "    same target value. The output is an array of balanced classes, i.e.\n",
    "    there are the same number of -1 as +1\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape (n_samples, n_features)\n",
    "        The data\n",
    "    y : array, shape (n_samples,) or (n_samples, 2)\n",
    "        Target labels. If it's a 2D array, the second column represents\n",
    "        the grouping of samples, i.e., samples with different groups will\n",
    "        not be considered.\n",
    "    Returns\n",
    "    -------\n",
    "    X_trans : array, shape (k, n_feaures)\n",
    "        Data as pairs\n",
    "    y_trans : array, shape (k,)\n",
    "        Output class labels, where classes have values {-1, +1}\n",
    "    \"\"\"\n",
    "    X_new = []\n",
    "    y_new = []\n",
    "    y = np.asarray(y)\n",
    "    if y.ndim == 1:\n",
    "        y = np.c_[y, np.ones(y.shape[0])]\n",
    "    comb = itertools.combinations(range(X.shape[0]), 2)\n",
    "    for k, (i, j) in enumerate(comb):\n",
    "        if y[i, 0] == y[j, 0] or y[i, 1] != y[j, 1]:\n",
    "            # skip if same target or different group\n",
    "            continue\n",
    "        X_new.append(X[i] - X[j])\n",
    "        y_new.append(np.sign(y[i, 0] - y[j, 0]))\n",
    "        # output balanced classes\n",
    "        if y_new[-1] != (-1) ** k:\n",
    "            y_new[-1] = - y_new[-1]\n",
    "            X_new[-1] = - X_new[-1]\n",
    "    return np.asarray(X_new), np.asarray(y_new).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankSVM(svm.LinearSVC):\n",
    "    \"\"\"Performs pairwise ranking with an underlying LinearSVC model\n",
    "    Input should be a n-class ranking problem, this object will convert it\n",
    "    into a two-class classification problem, a setting known as\n",
    "    `pairwise ranking`.\n",
    "    See object :ref:`svm.LinearSVC` for a full description of parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit a pairwise ranking model.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array, shape (n_samples, n_features)\n",
    "        y : array, shape (n_samples,) or (n_samples, 2)\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        X_trans, y_trans = transform_pairwise(X, y)\n",
    "        super(RankSVM, self).fit(X_trans, y_trans)\n",
    "        return self\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        return np.dot(X, self.coef_.ravel())\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict an ordering on X. For a list of n samples, this method\n",
    "        returns a list from 0 to n-1 with the relative order of the rows of X.\n",
    "        The item is given such that items ranked on top have are\n",
    "        predicted a higher ordering (i.e. 0 means is the last item\n",
    "        and n_samples would be the item ranked on top).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array, shape (n_samples, n_features)\n",
    "        Returns\n",
    "        -------\n",
    "        ord : array, shape (n_samples,)\n",
    "            Returns a list of integers representing the relative order of\n",
    "            the rows in X.\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'coef_'):\n",
    "            return np.argsort(np.dot(X, self.coef_.ravel()))\n",
    "        else:\n",
    "            raise ValueError(\"Must call fit() prior to predict()\")\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Because we transformed into a pairwise problem, chance level is at 0.5\n",
    "        \"\"\"\n",
    "        X_trans, y_trans = transform_pairwise(X, y)\n",
    "        return np.mean(super(RankSVM, self).predict(X_trans) == y_trans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3X2cnHV57/HPN5sBJopsLLGYhRBU\nCoJAsCvgofXIg0ZAIY0oUDn1sRytlEJpaiIUQl+2oGkFe/TUUqG1BSHIwxiOtEEKLT3YIImbGCLk\nEAEhE5SALA9mhc3udf6Ye8JkM4+7M3PPzn7fr1demb3ve+65Niz3tb+n66eIwMzMrF7T0g7AzMwm\nFycOMzNriBOHmZk1xInDzMwa4sRhZmYNceIwM7OGOHGYNZGkuZJC0vQm3OvdkjY3I65Wk/Tvkj6V\ndhzWHk4c1lEkPS5pSNKLkgYlfV/SpyXV9bPajAd38v63jPf9Zt3OicM60QciYk9gf+AK4HPANemG\n1D2a0Rqyqc2JwzpWRDwfESuAM4CPSnobgKRTJA1IekHSk5KWlrzt3uTvQUkvSXqnpDdLulvSs5Ke\nkXS9pN5ynymp+P51yfvPSI7/vqRNkn4haYWk2TXC/4SkLZKeknRhyf2nSVos6SdJPDdJen09/x6S\nZku6RdJWSY9JOq/k3FGS/itppT0l6auSdis5H5I+K+kR4JGSY5+W9Iik5yR9TZJK3vMJSQ8l51ZK\n2r/k3HskPSzpeUlfBXa8z7qfE4d1vIj4AbAZ+O3k0C+B3wN6gVOAz0hakJx7V/J3b0S8NiL+i8JD\n7XJgNvBWYD9gaYXPKr7/iOT9yyUdn7z/w8AbgZ8CN9YI+zjgQOC9wGJJJybHzwMWAP89iec54Gu1\n/g2SrrrbgXVAH3ACcL6k+cklI8AFwN7AO5PzfzDmNguAo4FDSo69H3gHcETy/c1PPm8B8HlgITAL\n+E/ghuTc3sAtwMXJ5/0EOLbW92BdJCL8x3865g/wOHBimeOrgIsqvOcq4Mrk9VwggOlVPmMBMFDl\nfABvKfn6GuBLJV+/FhgG5pZ5b/HzDy459iXgmuT1Q8AJJefemNxrl3iBdwObk9dHA0+MOb8E+IcK\n38P5wG1jvqfjy3yfv1Xy9U3A4uT1vwCfLDk3DdhGofvw94BVJedEIbF/Ku2fH/9pzx/3ddpk0Qf8\nAkDS0RTGPt4G7AbsDny70hslvQH4Gwotlj0pPASfa+CzZwM/LH4RES9JejaJ6fEK73my5PVPgcOS\n1/sDt0kaLTk/Avw6kK8Sw/7AbEmDJcd6KLQEkPQbwJeBfmAGMB1YUyWmop+VvN5GISkWP+8rkv66\n5LwofM+zS+8VESGp3L2tS7mryjqepHdQeGD93+TQt4AVwH4RsRfwdV7tYy9X7vny5PjhEfE64Gwa\n65PfQuFBWoznNcCvUf1Bv1/J6znJPaDwwD0pInpL/uwREdXuVXzfY2Pet2dEnJyc/1vgYeDA5Hv8\nPLt+j42Uwn4S+J9jPi8bEd8Hnir9/pJxkf0q3ci6jxOHdSxJr5P0fgrjCddFxPrk1J7ALyLiV5KO\nAn635G1bgVHgTSXH9gReojBg3gcsqvHRPx/z/m8BH5c0T9LuwF8C90fE41Xu8WeSZkg6FPg4sDw5\n/nXgL4oDzZJmSTqtRjwAPwBekPQ5SVlJPZLeliTV4vf4AvCSpIOBz9Rxz2q+DixJ4kfSXpI+lJz7\nLnCopIXJDK3zgH0m+Hk2iThxWCe6XdKLFH7rvYhCF8zHS87/AfDnyTWXUOibByAitgF/AdyXzDA6\nBrgMeDvwPIWH3q01Pn8p8M3k/R+OiH8D/ozCgPBTwJuBM2vc4z+ATcC/AX8VEXcmx79CobV0ZxL/\nKgrjF1VFxAjwAWAe8BjwDPANYK/kkj+hkEBfBP6eVxPVuETEbcAXgRslvQA8CJyUnHsG+BCF7sJn\nKUwCuG8in2eTiyK8kZOZmdXPLQ4zM2uIE4eZmTXEicPMzBrixGFmZg3pygWAe++9d8ydOzftMMzM\nJo01a9Y8ExGz6rm2KxPH3LlzWb16ddphmJlNGpJ+Wu+17qoyM7OGpJo4JF0r6WlJD1Y4/+6kbPPa\n5M8l7Y7RzMx2lnZX1T8CXwX+qco1/xkR729POGZmVkuqLY6IuJek4qmZmU0Ok2GM452S1kn6l2LB\nNTMzS0/aXVW1/BDYP9n/4GQgR6Gg2i4knQOcAzBnzpz2RWhmNsV0dOKIiBdKXt8h6X9L2jupzjn2\n2quBqwH6+/tdudGsA+QG8ixbuZEtg0PM7s2yaP5BLDiyL+2wKpps8aaloxOHpH2Anyc7jB1FoWvt\n2ZTDMrM65AbyLLl1PUPDIwDkB4dYcmthS5WJPoxb8YBvZbzdJtXEIekGCvsq7y1pM3ApkAGIiK8D\npwOfkbQdGALODNeBN5sUlq3cuOMhXDQ0PMKylRt3eRA3kgha9YBvJN5O0+6WUqqJIyLOqnH+qxSm\n65rZJLNlcKiu440mgkoP+AtvWlfxPc2Mt9Ok0VKaDLOqzGwSmt2bret4td/0y6n0IB+JYMmt68kN\n1Nq+vbx64+00jf77NYMTh5m1xKL5B5HN9Ox0LJvpYdH8g3Y6VikR5AeHyiaBag/yRh+YuYE8x15x\nNwcs/i6/fHk7mR7VjLfTpNFScuIws5ZYcGQfly88jL7eLAL6erNcvvCwXbpPqiWCci2IcgmpVL0P\nzGIXT35wiAAGh4YhYOaMTNV4O00aLaWOnlVlZpPbgiP7aj54F80/aKc++lLlBqeLry+8aR0jZebK\n1PvALNfFMzwazNhtOgOXvLfqeztp2m65f79Wt5ScOMxs3Mo9QIGGHqrFc+cvX1v2fLkWRPE9jTww\nx8aaH2cXT6dN2y1+ZjsTmbpxdmt/f394Pw6z1hr7AK0km+nhg7/Zxz0Pb636YDv2irvLPsz7erPc\nt/j4XT572cqN5AeH6JEYiaCvygOzXKwCyj39yn3eeOOcTCStiYj+eq51i8PMqir3kC7+XY+h4RGu\nX/XEjod0ud/QcwN5fvny9l3eW64FMTYJjETsuK7Sb9nluqWCXZNHPV08k3XabjN5cNzMKiodQAZ2\nJIt6k0bR2KtLZz8VP2NwaHina2bOyOw0OF2cAXX+8rUNTz+t9FAPqDl4P9ZknbbbTG5xmFlF5X5T\nb5biw7zSZ8zYbfpOSaNWt1i13/grjWmMp3spjcHoTuPEYWY71DuA3AzF39Dr6fqpJ4FV+42/mQ/7\nNAajO40Th5kB5WcLtYqA4w6eBVRuDZQmglrjB7WSQLMf9vVMM+5mThxmBoy/WyozTYwCI6P1j3sE\ncMuaPP37v76u1kC11k+12VSlpvrDvpk8OG42xeUG8sy77M5xtzC2j0ZDSaOodHFfrRXmlcqXXHXG\nPO5bfLwTQpu5xWE2heUG8iz69jqGx/HgL6r2zh6J0YiK1xS7oGq1Bjyu0FmcOMy6WK3SGEtXbJhQ\n0qhlNILHrjil4qK5Rqawuqupc7iryqxLjS3ilx8c4vzla5l32Z3kBvLkBvK7rJ1otmJiqLdSrk0O\nbnGYdZnSld7lDA4NV6wL1UylicFdTd3FicOsi9RbP2oipgnG9m7VU4/KXU3dw4nDrIu0cqV30WjA\nVWfMc+thCnPiMOsCtbqnmqlHcuthinPiMJvk2tE9VarRAofWfZw4zCapdrYySvVNoSqwVp4Th9kk\n1OpWRnG/jfHsV2Hdz+s4zCahVg+Cj0bw+BWncOUZ8xrer8K6n1scZpNQq3ebKy7c8yC4lZNqi0PS\ntZKelvRghfOS9DeSNkn6kaS3tztGs07UOyPTtHuNfQi4O8pqSbur6h+B91U5fxJwYPLnHOBv2xCT\nWcd76VfNKxWy14yMu6OsIal2VUXEvZLmVrnkNOCfIiKAVZJ6Jb0xIp5qS4BmHSg3kGd4tHn3G9w2\nzMAl723eDa3rdfoYRx/wZMnXm5NjuyQOSedQaJUwZ86ctgRn1m4X59Zz/aonmnrPRirUmkHnJw6V\nOVZ29VFEXA1cDdDf3+8VStY1Wrlew+MZNh6dnjg2A/uVfL0vsCWlWMzabqLrNWbOyPCr4dGd3l9c\nm1HvlqtmY3V64lgBnCvpRuBo4HmPb9hUMtH1GoPbhrnSBQmtyVJNHJJuAN4N7C1pM3ApkAGIiK8D\ndwAnA5uAbcDH04nULB0TXa8xuzfrtRjWdGnPqjqrxvkAPtumcMw6zuze7LjHNjI98viFtUTa6zjM\nrIrjDp5VdoZILa/ZrYdlpx/hloa1RKePcZhNWbmBPLesyZefRlhBbzbD0lMPdcKwlnLiMOtQjQ6M\nX3XGPCcMawt3VZl1qEYGxou78pm1gxOHWYfJDeSZd9mdDXVRnXX0frUvMmsSd1WZdZDcQJ5F317H\n8Gh9aWOa4HePnsMXFhzW4sjMXuXEYdZBlq7YUFfSyGamcfnCw909Zalw4jDrELmBPINDlculC3js\nilPaF5BZBR7jMOsAuYE8F960ruo1rmJrncKJwyxlxUKGI1G9i8qrwK1TOHGYpaze9Roez7BO4cRh\nlrJ61mv0uZvKOogTh1nKao1deLMl6zSeVWWWknp39rt84WHuprKO4sRhloLi3uHe49gmI3dVmbVZ\nbiDfUNJYcut6cgP5lsZk1ggnDrM2W7ZyY0MtjaHhEZat3NiyeMwa5cRh1mbj2Q52olvImjWTE4dZ\nm41nBbhXjVsnceIwa7NGp9Z6Oq51Gs+qMuswvdkMEgxuG2Z2b5ZF8w/ydFzrKE4cZm2SG8hz2e0b\neG5b5Qq4AGsvfW+bIjIbHycOszYoFjJsZA9xs07lMQ6zNqi3kGE24/8lrfOl+lMq6X2SNkraJGlx\nmfMfk7RV0trkz6fSiNNsomqVFSm6fOHhLY7EbOJS66qS1AN8DXgPsBl4QNKKiPjxmEuXR8S5bQ/Q\nrElyA3kENRf9ZTPTPAhuk0KaLY6jgE0R8WhEvALcCJyWYjxmLVHvSvE9Mj0tj8WsGdJMHH3AkyVf\nb06OjfVBST+SdLOk/SrdTNI5klZLWr1169Zmx2o2bvWu+h6sMdvKrFOkmThU5tjYX8xuB+ZGxOHA\nXcA3K90sIq6OiP6I6J81a1YTwzSbmHpXfXt1uE0WaSaOzUBpC2JfYEvpBRHxbES8nHz598Bvtik2\ns6Y57uDav8h4dbhNJmkmjgeAAyUdIGk34ExgRekFkt5Y8uWpwENtjM+sKe55uHrXaW82482abFJJ\nbVZVRGyXdC6wEugBro2IDZL+HFgdESuA8ySdCmwHfgF8LK14zcar2lTcq86Y54Rhk06qK8cj4g7g\njjHHLil5vQRY0u64zJrl4tz6iuf6erNOGjYpeZmqWYsUd/orRzReJdesUzhxmLVItfUbAW5t2KTl\nxGHWItXWb/R56q1NYk4cZi2yVzZT8Zy7qWwyc+IwaxGXULdu5cRh1gIX59bz8vbRiueXrdzYxmjM\nmsuJw6wFbrj/yarn661fZdaJnDjMmiw3kGckqtfD7Z1RefzDrNN561izJro4t57rKqzdKFUjr5h1\nNLc4zJokN5CvK2kAPD/kEuo2eTlxmDVJIwPeLqFuk5kTh1mT1LuvuEuo22TnxGHWBLmBfF3XuYS6\ndQMPjps1QT3dVL3ZDGsvfW8bojFrLbc4zJqg1rqMbKaHpace2qZozFrLicOsCarVpQLcPWVdxYnD\nrAmGRyqXFzHrNk4cZk3wy1eqFzR0bSrrJk4cZhNUz4wq16aybuLEYTZB9bQmvODPuokTh9kE1dOa\n8II/6yZOHGYTVKvSbW824xlV1lWcOMwm6OUaO/15/YZ1GycOswm4OLeebcPVp+K6tWHdxonDbJxy\nA3mur1FGvc+D4taFUk0ckt4naaOkTZIWlzm/u6Tlyfn7Jc1tf5Rm5V12+waq7ceU6ZEHxa0rpZY4\nJPUAXwNOAg4BzpJ0yJjLPgk8FxFvAa4EvtjeKM3Kyw3keW5b5c2YJFh2+hHuprKulGaL4yhgU0Q8\nGhGvADcCp4255jTgm8nrm4ETJKmNMZqVVW3thoArPzzPScO6VpqJow94suTrzcmxstdExHbgeeDX\nyt1M0jmSVktavXXr1haEa/aqams3PnLMHCcN62o1E4ekcyXNbMFnl2s5jO0yrueawsGIqyOiPyL6\nZ82aNeHgzKqptBK8N5vhCwsOa3M0Zu1VT4tjH+ABSTclg9nN6iraDOxX8vW+wJZK10iaDuwF/KJJ\nn282bovmH0Q207PTMe+5YVNFzcQRERcDBwLXAB8DHpH0l5LePMHPfgA4UNIBknYDzgRWjLlmBfDR\n5PXpwN0RUW0ii1nb7JF59X8fbwlrU0ldW8dGREj6GfAzYDswE7hZ0vci4k/H88ERsV3SucBKoAe4\nNiI2SPpzYHVErKCQrP5Z0iYKLY0zx/NZZs30kb//L+77yc4N35e3ez8OmzpU6xd4SedR+K3/GeAb\nQC4ihiVNAx6JiIm2PJquv78/Vq9enXYY1oXe8+V/55Gnf1n2XF9vlvsWH9/miMyaQ9KaiOiv59p6\nWhx7Awsj4qelByNiVNL7xxOg2WR0cW59xaQB3nPDpo6aiSMiLqly7qHmhmPWuW64/8mq573nhk0V\nrlVlVqeRGt26Li9iU4UTh1mdplWZiL5bjzyjyqYMJw6zOu0+vfL/LsMjniVuU4cTh1mdhqrsu+Hx\nDZtKnDjM6pAbyFc97/ENm0qcOMxqyA3kufDb66pe4/ENm0qcOMxquOz2DYyMVh7D6M1m2hiNWfqc\nOMxqqLZhExQ2bTKbSpw4zCZosEZiMes2ThxmE+QZVTbVOHGY1TBzRuUxjGymxzOqbMqpq6y62VST\nG8izdMUGBocqd0P1ZjMsPfVQz6iyKceJw2yM3ECeRd9ex3CVmVTTwEnDpix3VZmNsWzlxqpJA2A0\nuc5sKnLiMBuj3n01vP+GTVVOHGZj1DtLyrOpbKpy4jAb47iDZ9V1nWdT2VTlxGFWIjeQ55Y11Qsa\nApx9zBwPjNuU5VlVZiWWrdzI0PDILseLVUVm92ZZNP8gJw2b0pw4zEpUGvAO4Koz5jlhmOGuKrOd\nVBvw9vRbswInDrMS1Qa8Pf3WrCCVxCHp9ZK+J+mR5O+ZFa4bkbQ2+bOi3XHa1LPgyL6Ktak8/das\nIK0xjsXAv0XEFZIWJ19/rsx1QxExr72h2VSUG8hz2e0bKu694WKGZq9Kq6vqNOCbyetvAgtSisOs\nUJvq5nUVk4aAD/5mnwfGzRJpJY5fj4inAJK/31Dhuj0krZa0SlLV5CLpnOTa1Vu3bm12vNalcgN5\nLli+luGRyrWpArjnYf9MmRW1rKtK0l3APmVOXdTAbeZExBZJbwLulrQ+In5S7sKIuBq4GqC/v796\nhTozXq2CW88PiwfGzV7VssQRESdWOifp55LeGBFPSXoj8HSFe2xJ/n5U0r8DRwJlE4dZo+qpglvk\ngXGzV6XVVbUC+Gjy+qPAd8ZeIGmmpN2T13sDxwI/bluE1vUaaUV4YNzsVWkljiuA90h6BHhP8jWS\n+iV9I7nmrcBqSeuAe4ArIsKJw5qm3lZEbzbjgXGzEqlMx42IZ4ETyhxfDXwqef194LA2h2ZTyKL5\nB/HHN62lVm/V0lMPbU9AZpOEa1XZlJMbyLNs5Ua2DA7VHBgXuLVhNoYTh00puYE8S25dX7YCbjme\nnme2K9eqsimlUtn0Svo8m8psF04cNqU0MpNKeDaVWTlOHDal9FYoYFjOR7zLn1lZThw2ZeQG8rz0\nq+11XTsjM40vLPCkPrNyPDhuU0JuIM+FN61jJOob7h4aHm1xRGaTl1sc1vWKM6nqTRrgEiNm1Thx\nWNdrdCYVeFDcrBonDut6jVa2dYkRs+qcOKyr5QbySPVfn830uMSIWQ0eHLeuVRzbqFaLavfp08hm\nenh+aJjZvVkWzT/IrQ2zGpw4rGvVM7bxyvZRvvjBw50szBrgrirrWvWMbQSFBGNm9XPisK5V7ypx\nbwtr1hgnDutKF+fW89y24bqu9ZoNs8Y4cVjXyQ3kuX7VE3Vf7zUbZo1x4rCuUiwtUu8a8ZkzvGbD\nrFFOHNY1Gi0tks30cOkHvGbDrFFOHNY1GiktMk1w+cLD3NowGwcnDusajcyOqrYo0Myqc+KwrrFX\ntv5NmsDrN8zGyyvHbVLJDeRZtnIjWwaHmN2b5biDZ3HPw1vZMjjUUE0q8PoNs/Fy4rBJozj4XRzH\nyA8OcV3JtNsGttsAvH7DbLxS6aqS9CFJGySNSuqvct37JG2UtEnS4nbGaJ1nPPtqVJLN9Hj9htk4\npTXG8SCwELi30gWSeoCvAScBhwBnSTqkPeFZJ8o3qWuprzfrGVVmE5BKV1VEPASg6p3SRwGbIuLR\n5NobgdOAH7c8QOtK2UyPE4ZZE3TyGEcf8GTJ15uBoytdLOkc4ByAOXPmtDYya5mxg9/N2h+jR3LS\nMGuSliUOSXcB+5Q5dVFEfKeeW5Q5VnH4MyKuBq4G6O/v9yz9Sajc4PeSW9cDsODIPnqkuleFjzUa\n4aRh1iQtSxwRceIEb7EZ2K/k632BLRO8p3WwcoPfQ8MjXHjTOi5YvpY9MtMYGh5f4vAMKrPm6eQF\ngA8AB0o6QNJuwJnAipRjshaqNPg9EkEAQ8Oj47qvZ1CZNVda03F/R9Jm4J3AdyWtTI7PlnQHQERs\nB84FVgIPATdFxIY04rXWyw3km3KfTI84+5g59PVmEZ5BZdYKac2qug24rczxLcDJJV/fAdzRxtCs\nhaoNfC+59UdN+Yzp08QXFhzWlHuZWXmdPKvKukitge/xdkON1az7mFllThzWdKUti94ZGSJgcGjX\nbVyHhke47PYNLjZoNsk4cVhTjW1Z1Nr3+7ltw3XvDV6PmTMaq5BrZo3r5FlVNgk1s55UozI98o5+\nZm3gFodNWGnXVLtWXhYXAxb/7mviKnMzq86JwyZkbNdUO7jmlFm6nDhs3HIDeS68ad24y4A0okdi\nNKKp9avMbHycOKyqSmsvii2NdiQNKNSaeuyKU9ryWWZWnRPHFHJxbj033P/kjrGBs47eb5fFcqWJ\nYq9shhdf3s7IaCE55AeHOH/5Ws5fvrbtsbvWlFnncOKYIi7Ord9pm9WRCK5b9QS3rtnM0PDojv27\nb1mT3zFeUW7tRRpca8qsszhxTBHfuv+Jsse3JSut84NDXL/qibbNiirnNbv1kOmZxuDQsGdLmXUw\nJ44pIDeQZ7SOjJBm0rjqjHlODmaThBcATgGdUtJj9+nlf9xmzsg4aZhNIk4ck0xuIM+xV9zNAYu/\ny7FX3F1XOfJK+1y0U19vli9+8HAyPTtv7OjV3maTj7uqOlS5abBA1QqzlUxky9VmKR2naMWe4mbW\nPoqUHyit0N/fH6tXr27oPdX2imi3cquxs5ke9shMq1gQsHR67djqtPUUEezNZpDKFyXs681OuNXy\nuNdgmHU0SWsior+ea91VxasP6nxSa6n4m3yzdqVr1NIVG8ruvV0tARSn185d/F0uWL52x/dSb+XZ\n1+w+nUs/cCjZTM9Ox4tTYfsmsI6iN+uKtWbdxF1VlK/oOjQ8wrKVGyfU6hhPKyY3kJ/w+onxtCG3\nDA7V7EqqVZNKZT47M00sPdVjGGbdxImDwkOzkeP1yA3kWXTzOoZHdl51vfqnv6i6WrsaCVrVs1hc\nmb3gyL6yya00qeQHh3ZJEsXCg8VrOqHLz8xaw4mDwkOzXB/+RMpcXHb7hh1Jo9R1q56gf//X73iY\nNlJdtlVJo96V2aVJpVpryonCrLs5cVCY8VNuMHoiZS6qjS2UdoGlufERFNZQXPqBQxt+2FdqmZhZ\n93PigLZPEy3tkppIdxhUnmpb7EqaOSPDr4ZHGEpKixS7u1zKw8zGy4kj0ezfoHuzmYqD3KVdYJW6\nyerR15vlvsXHA501ndjMupsTR4ssPfVQ/nj5WkbHHM/0aKcusEXzD+KC5Wsbngml5L1F7joys3bx\nOo4WWXBkH18+Y95Oaxhmzsiw7PQjdnrALziyj48cMweVu0kFAj5yzBwnCjNLRSorxyV9CFgKvBU4\nKiLKLvOW9DjwIjACbK93VeN4Vo6PV7O6iMZuoCTB4LbhHftk3PPwVndDmVnLNLJyPK2uqgeBhcDf\n1XHtcRHxTIvjGZexU2nrrR1VjruazGyySKWrKiIeiojOqPU9AdVWnJuZdatOH+MI4E5JaySdU+1C\nSedIWi1p9datW9sSXCtWnJuZdbqWdVVJugvYp8ypiyLiO3Xe5tiI2CLpDcD3JD0cEfeWuzAirgau\nhsIYx7iCblArVpybmXW6liWOiDixCffYkvz9tKTbgKOAsokjDa1YcW5m1uk6tqtK0msk7Vl8DbyX\nwqB6x1hwZB+XLzyMvt4sorAg7/KFh3mQ28y6WiqzqiT9DvC/gFnAdyWtjYj5kmYD34iIk4FfB26T\nVIzzWxHxr2nEW41nQ5nZVJNK4oiI24DbyhzfApycvH4UOKLNoZmZWQ0d21VlZmadyYnDzMwa4sRh\nZmYNceIwM7OGOHGYmVlDUqmO22qStgI/beNH7g10ZCHGMhxrazjW1nCsrVEu1v0jYlY9b+7KxNFu\nklbXW444bY61NRxrazjW1phorO6qMjOzhjhxmJlZQ5w4muPqtANogGNtDcfaGo61NSYUq8c4zMys\nIW5xmJlZQ5w4zMysIU4cTSTpDyVtlLRB0pfSjqcWSX8iKSTtnXYslUhaJulhST+SdJuk3rRjGkvS\n+5L/7pskLU47nkok7SfpHkkPJT+jf5R2TNVI6pE0IOn/pB1LNZJ6Jd2c/Jw+JOmdacdUiaQLkv/2\nD0q6QdIe47mPE0eTSDoOOA04PCIOBf4q5ZCqkrQf8B7gibRjqeF7wNsi4nDg/wFLUo5nJ5J6gK8B\nJwGHAGdJOiTdqCraDlwYEW8FjgE+28GxAvwR8FDaQdThK8C/RsTBFLaC6MiYJfUB5wH9EfE2oAc4\nczz3cuJons8AV0TEy1DY7jbleGq5EvhToKNnR0TEnRGxPflyFbBvmvGUcRSwKSIejYhXgBsp/ALR\ncSLiqYj4YfL6RQoPuI7chUzSvsApwDfSjqUaSa8D3gVcAxARr0TEYLpRVTUdyEqaDswAtoznJk4c\nzfMbwG9Lul/Sf0h6R9oBVSJiETg7AAAE5ElEQVTpVCAfEevSjqVBnwD+Je0gxugDniz5ejMd+jAu\nJWkucCRwf7qRVHQVhV9sRtMOpIY3AVuBf0i61b6RbHXdcSIiT6En5AngKeD5iLhzPPdKZQfAyUrS\nXcA+ZU5dROHfciaFLoB3ADdJelOkNN+5Rqyfp7CHe0eoFmtEfCe55iIKXS3XtzO2OqjMsY5uxUl6\nLXALcH5EvJB2PGNJej/wdESskfTutOOpYTrwduAPI+J+SV8BFgN/lm5Yu5I0k0Jr+ABgEPi2pLMj\n4rpG7+XE0YCIOLHSOUmfAW5NEsUPJI1SKCS2tV3xlaoUq6TDKPzgrEv2c98X+KGkoyLiZ20McYdq\n/64Akj4KvB84Ia1EXMVmYL+Sr/dlnM3/dpCUoZA0ro+IW9OOp4JjgVMlnQzsAbxO0nURcXbKcZWz\nGdgcEcWW280UEkcnOhF4LCK2Aki6FfhvQMOJw11VzZMDjgeQ9BvAbnRgpcyIWB8Rb4iIuRExl8IP\n/tvTShq1SHof8Dng1IjYlnY8ZTwAHCjpAEm7URhsXJFyTGWp8JvCNcBDEfHltOOpJCKWRMS+yc/n\nmcDdHZo0SP6/eVLSQcmhE4AfpxhSNU8Ax0iakfwsnMA4B/Ld4miea4FrJT0IvAJ8tAN/O56Mvgrs\nDnwvaSGtiohPpxvSqyJiu6RzgZUUZqlcGxEbUg6rkmOB/wGsl7Q2Ofb5iLgjxZi6wR8C1ye/ODwK\nfDzleMpKutJuBn5Iodt3gHGWHnHJETMza4i7qszMrCFOHGZm1hAnDjMza4gTh5mZNcSJw8zMGuLE\nYVanpFrrGknvKjl2p6QPtenzz0uqr3ba6nmbYjwd16yGZH5+JiJ+KeloCoX33g6cDnwsIua3KY6H\ngZMi4jFJewEvRkSn13KyLuQWh1kFkt4q6a+BjRSKWJKUlvg+sBT4S+CzddznLZLukrRO0g8lvVkF\ny5J9EdZLOqPk+kWSHkj2ILksOfZ1CgX1Vki6APgtYKOkpZLmNPlbN6vKK8fNSiSVTT8MfJJCAcN/\noLDHyoslly2hUBH3qojYVMdtr6dQcv+2ZOOcacBCYB6F/Rv2Bh6QdC9wGHAghXLtopAo3hURn07K\nrxwXEc8ksd4PnA18R9LTFFpC30nKu5u1jBOH2c6eAn4EfCoiHq5wzbuA54G31bqZpD2Bvoi4DSAi\nfpUc/y3ghogYAX4u6T8oVFV+F4XKxQPJLV5LIZHcO/beSQK5Crgq2XXuWgpVWQ+v71s1Gx93VZnt\n7HQgD9wm6RJJ+5eeTFokX6JQ0HJWUsG1mnJl12sdvzwi5iV/3hIR11S8uXSIpGXAP1PoQvv9GvGY\nTZgTh1mJZMfBMyiMITxPoRvormTjI4BLgJuS1sgfAFcW922W9E+SjhpzvxeAzZIWJNfsLmkGhRbE\nGclMrVkUWho/oFAs8RPJnhlI6pP0hrFxSnq7pFUUuqceBuZFxCdLynubtYxnVZnVkCSDp4A9KZTP\nPyIihpJzfwM8GxGXJRVnPxART455/4HA31EYyxgGPgQ8RqHlchKFjZ++EBHLk+v/CPhU8vaXgLMj\n4ieSHqewX/Qzkt4KEBEdub+1dTcnDrMmSPaeviYi2rKmwyxNThxmZtYQj3GYmVlDnDjMzKwhThxm\nZtYQJw4zM2uIE4eZmTXEicPMzBry/wEn7OprD3HiwAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x191ca534fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of ranking  0.986440677966\n",
      "Performance of ranking  0.978787878788\n",
      "Performance of linear regression  0.958757062147\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "n_samples, n_features = 300, 5\n",
    "true_coef = np.random.randn(n_features)\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "noise = np.random.randn(n_samples) / np.linalg.norm(true_coef)\n",
    "y = np.dot(X, true_coef)\n",
    "y = np.arctan(y) # add non-linearities\n",
    "y += .1 * noise  # add noise\n",
    "Y = np.c_[y, np.mod(np.arange(n_samples), 5)]  # add query fake id\n",
    "cv = cross_validation.KFold(n_samples, 5)\n",
    "train, test = next(iter(cv))\n",
    "\n",
    "# make a simple plot out of it\n",
    "import pylab as pl\n",
    "pl.scatter(np.dot(X, true_coef), y)\n",
    "pl.title('Data to be learned')\n",
    "pl.xlabel('<X, coef>')\n",
    "pl.ylabel('y')\n",
    "pl.show()\n",
    "\n",
    "# print the performance of ranking\n",
    "rank_svm = RankSVM().fit(X[train], Y[train])\n",
    "\n",
    "\n",
    "X_train_trans, y_train_trans = transform_pairwise(X[test], y[test])\n",
    "X_test_trans, y_test_trans = transform_pairwise(X[test], y[test])\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "clf.fit(X_train_trans, y_train_trans)\n",
    "print('Performance of ranking ', clf.score(X_test_trans, y_test_trans))\n",
    "print('Performance of ranking ', rank_svm.score(X[test], Y[test]))\n",
    "\n",
    "# and that of linear regression\n",
    "ridge = linear_model.RidgeCV(fit_intercept=True)\n",
    "ridge.fit(X[train], y[train])\n",
    "X_test_trans, y_test_trans = transform_pairwise(X[test], y[test])\n",
    "score = np.mean(np.sign(np.dot(X_test_trans, ridge.coef_)) == y_test_trans)\n",
    "print('Performance of linear regression ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.10224037, -0.83604315, -0.71212664, -1.43457554,  1.1286637 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_svm.coef_.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.loc[201570]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readXML(path):\n",
    "    \"\"\"\n",
    "    Read XML file into a dictionary\n",
    "    \"\"\"\n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    dataset = pd.DataFrame(columns=['QID', 'QAID'], dtype=int)\n",
    "    \n",
    "    for Question in root:\n",
    "        QID = int(Question.get('QID'))\n",
    "        Qtext = Question.find('Qtext').text\n",
    "        \n",
    "        for QApair in Question.iter('QApair'): \n",
    "            QAID = int(QApair.get('QAID'))\n",
    "            QArel = QApair.get('QArel')\n",
    "            QAconf = QApair.get('QAconf')\n",
    "            QAquestion = QApair.find('QAquestion').text\n",
    "            QAanswer = QApair.find('QAanswer').text\n",
    "            \n",
    "            dataset = dataset.append({'QID': QID,\n",
    "                                    'QAID': QAID,\n",
    "                                    'Qtext': Qtext,\n",
    "                                    'QAquestion': QAquestion,\n",
    "                                    'QAanswer': QAanswer,\n",
    "                                    'QArel': 0 if QArel == 'I' else 1,\n",
    "                                    'QAconf': QAconf}, ignore_index=True)\n",
    "            \n",
    "    dataset.set_index(['QID', 'QAID'], inplace=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = readXML('../TRAIN/SemEval2016-Task3-CQA-MD-train.xml')\n",
    "test_dataset = readXML('../TEST/2017/SemEval2017-Task3-CQA-MD-test.xml')\n",
    "\n",
    "train_dataset = train_dataset.sort_index(level=0, ascending=[False, True])\n",
    "train_dataset = train_dataset.reset_index().drop_duplicates().set_index(['QID', 'QAID'])\n",
    "\n",
    "test_dataset = test_dataset.sort_index(level=0, ascending=[False, True])\n",
    "test_dataset = test_dataset.reset_index().drop_duplicates().set_index(['QID', 'QAID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import wordpunct_tokenize\n",
    "from nltk.stem import ISRIStemmer\n",
    "\n",
    "class StemTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = ISRIStemmer()\n",
    "    def __call__(self, doc):\n",
    "         return [self.wnl.stem(t) for t in wordpunct_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lsa = Pipeline([('tfidf', TfidfVectorizer(min_df=1, max_df=0.1, tokenizer=StemTokenizer(), stop_words=stopwords.words('arabic'), smooth_idf=False, sublinear_tf=True, norm='l2', max_features=1000)),\n",
    "                      ('lsa',  TruncatedSVD(n_components=900,n_iter=3)),\n",
    "                      ('normalizer', Normalizer(copy=False))])\n",
    "train_lsa.fit(list(set(train_dataset['Qtext'])))\n",
    "\n",
    "test_lsa = Pipeline([('tfidf', TfidfVectorizer(min_df=1, max_df=0.1, tokenizer=StemTokenizer(), stop_words=stopwords.words('arabic'), smooth_idf=False, sublinear_tf=True, norm='l2', max_features=1000)),\n",
    "                ('normalizer', Normalizer(copy=False))])\n",
    "test_lsa.fit(list(set(test_dataset['Qtext'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_query_vec = train_lsa.transform(train_dataset['Qtext'])\n",
    "train_question_vec = train_lsa.transform(train_dataset['QAquestion'] + train_dataset['QAanswer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_question_vec\n",
    "Y_train = np.c_[train_dataset['QAconf'].astype(np.float), train_dataset.reset_index()['QID']]\n",
    "\n",
    "X_valid = X_train[int(X_train.shape[0] * 0.8):]\n",
    "Y_valid = Y_train[int(Y_train.shape[0] * 0.8):]\n",
    "\n",
    "X_train = X_train[:int(X_train.shape[0] * 0.8)]\n",
    "Y_train = Y_train[:int(Y_train.shape[0] * 0.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the performance of ranking\n",
    "rank_svm = RankSVM().fit(X_train, Y_train)\n",
    "print('Performance of ranking ', rank_svm.score(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings = []\n",
    "for QID, data in test_dataset.groupby(level=0):\n",
    "    test_query_vec = test_lsa.transform(data['Qtext'])\n",
    "    test_question_vec = test_lsa.transform(data['QAquestion'] + data['QAanswer'])\n",
    "    X_test = test_question_vec\n",
    "    # print the performance of ranking\n",
    "    ranking = rank_svm.predict(X_test.toarray())\n",
    "    rankings.append(1+ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_list = []\n",
    "for ranking in rankings:\n",
    "    for rank in ranking:\n",
    "        ranking_list.append(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query_vec = test_lsa.transform(test_dataset['Qtext'])\n",
    "test_question_vec = test_lsa.transform(test_dataset['QAquestion'] + test_dataset['QAanswer'])\n",
    "\n",
    "similarities = [1 - cosine(query.reshape(-1, 1), question.reshape(-1, 1)) for query, question in zip(test_query_vec, test_question_vec)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset['Score'] = similarities\n",
    "test_dataset['Relevance'] = ['true' if similarity > 0.5 else 'false' for similarity in similarities]\n",
    "test_dataset['Rank'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAP(gold_dataset, pred_dataset, th=10):\n",
    "    dataset = pred_dataset.join(gold_dataset, lsuffix='_pred', rsuffix='_gold')[['Score_pred', 'Relevance_gold']].reset_index()\n",
    "    dataset = dataset.sort_values(['QID', 'Score_pred'], ascending=False)\n",
    "    dataset['Rank_pred'] = dataset.groupby('QID')['Score_pred'].rank(ascending=False)\n",
    "    dataset = dataset[dataset.Relevance_gold]\n",
    "    dataset = dataset[dataset.Rank_pred <= th]\n",
    "    dataset['Position'] = dataset.groupby('QID')['Rank_pred'].rank(ascending=True)\n",
    "    dataset['Precision'] = dataset.Position / dataset.Rank_pred\n",
    "    AP = dataset.groupby('QID')['Precision'].mean()\n",
    "    return round(AP.sum() / len(pred_dataset.groupby('QID')),4) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_dataset = pd.read_csv('../EVAL/SemEval2017-Task3-CQA-MD-test.xml.subtaskD.relevancy', sep='\\t',  names=['QID', 'QAID', 'Rank', 'Score', 'Relevance'], index_col=['QID', 'QAID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP(gold_dataset, test_dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
